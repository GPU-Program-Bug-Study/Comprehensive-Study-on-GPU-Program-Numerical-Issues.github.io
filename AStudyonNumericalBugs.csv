Link,Issue description,brief description,issue summary,root cause,Symptom,Fix 
"""https://github.com/ray-project/ray/issues/7853""","""[rllib] ValueError: Reward should be finite scalar, got nan (<class 'float'>)""",Nan issue. bug is hard to reproduce because it is caused by numerical issues that happen only when the underlying neural network learns parameters that are too big for a DiagGaussian action distribution,got nan (value error)-parameters that are too big ,special value bugs, crash,fix parameter
"""https://github.com/pyvista/pyvista/issues/1010""","""pyvista.add_arrows argument 'mag' producec error when using float""",,casting error/type error,accuracy issue,crash,fix the method 
"""https://github.com/pytorch/pytorch/issues/48576""","""how to avoid the precision loss(float32) caused by the gradient accumulation of Ring Allreduce in the case of ddp""",precision loss(float32) caused by the gradient accumulation of Ring Allreduce in the case of ddp,precision loss,accuracy issue,different results,ordering the configurations/rings used
"""https://github.com/pytorch/audio/issues/771""","""Ã°Å¸Ââ€º Bug: SoxEffectsChain returns wrong result for float32 wav""",SoxEffectsChain returns wrong result for 32 bit floating point WAV format. Torchaudio in audio domain. ,correctness issue/deprecated method use,correctness bug,wrong result ,update/use the new function 
"""https://github.com/napari/napari/issues/1854""","""Tab completion in QT console causes float divide by zero error""","Divide by Zero Error. When trying do to tab completion in the Qt console the current master, get a float divide by zero error popping up.",divide by zero ,correctness bug,crash,correct parameters
"""https://github.com/jiesutd/NCRFpp/issues/158""","""ZeroDivisionError: float division by zero""",ZeroDivisionError: float division by zero,divide by zero ,correctness bug,crash,use large parameters
"""https://github.com/apache/incubator-mxnet/issues/19472""","""[Bug][2.0] GluonNLP BART model float16 error""","Incompatible attr in node batch_dot at 1-th input: expected float32, got float16",incompatible attribute,correctness bug,error,use correct function
"""https://github.com/ROCmSoftwarePlatform/AMDMIGraphX/issues/210""","""python API faults on float16 example where float32 works""",Change instances of 32 to 16 and it now faults,truncate error/fp16 support ,correctness bug,error,python 2 does not support fp16. python 3 supports
"""https://github.com/pytorch/pytorch/issues/48163""","""nn.functional.interpolate backward in fp16 is extremely slow""",fp16 gives me 3.3s while fp32 gives 1.5s. This is not that surprising giving fp16 atomic add used during backward.,build issue atomic operation/scalar specific  cuda version,Environment issue,slow performance,update version
"""https://github.com/pytorch/fairseq/issues/2907""","""--fp16 utlizes significantly higher memory and results in OOM""",fp16 seems to take up >2x memory on GPU compared to fp32.  mixed precision training requires Volta or Turing architecture,memory usage issues/results OOM,Environment issue,high memory utilization (bad performance),change version pytorch 
"""https://github.com/huggingface/transformers/issues/8559""","""TFGPT2LMHeadModel fp16 support""",cannot compute Mul as input #1(zero-based) was expected to be a half tensor but is a float tensor ,type error fp16 != fp32/mixed precision support,correctness bug,crash,using correct data types
"""https://github.com/huggingface/transformers/issues/8403""","""[s2s finetune] huge increase in memory demands with --fp16""",--fp16 causes a 10x+ increase in gpu memory demands.,memory issue with fp16/ high memory use,environmental issue,perfomance,change version pytorch 
"""https://github.com/NVIDIA/TensorRT/issues/572""","""fp16 mode takes much more time than fp32""","fp32 30ms per frame, fp16 mode takes about 90ms per frame with the same input",issues due to compiler optimizations ,correctness bug,bad performance,update version
"""https://github.com/tensorflow/tensorflow/issues/43845""","""\""No gradients provided\"" with GradientDescentOptimizer if not using float variable""","The gradient descent optimizer gives ""No gradients provided"" error when minimizing it, if the variables used in the custom loss function are not explicitly defined as float",value error/not defined data type,correctness bug,error,fix data type
"""https://github.com/tensorflow/tensorflow/issues/34849""","""TF 2.0 - WARNING - dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32""",TF 2.0 - WARNING - dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32,automatic casting ,correctness bug,error,fix data type
"""https://github.com/tensorflow/tensorflow/issues/23861""","""matmul with large matrices fails with float16, but succeeds with float32""","Matmul fails with large float16 matrices. If you reduce the size of the matrix to 8e6, the code runs. If you keep the size of the matrix the same, but change all the data types to float32, it runs. T",data type issue fp16 fails and fp32 succeeds,correctness bug,error,change tf-nightly version
"""https://github.com/tensorflow/probability/issues/1127""","""Lack of tfd.Categorical support on CPU in XLA in float64""","workaround is to represent the logits in float32 rather than float64, but of course we should get the float64 version working too.",no support for float 64,correctness bug,error,update in new version 
"""https://github.com/rapidsai/cudf/issues/6429""","""[BUG] Performing `to_pandas` in `to_json` results in conversion to float columns when there is a null value present""","use pandas json writer, we perform .to_pandas in the code:This results in conversion of columns having nulls into float64 dtype",null values,special value bugs,different results ,correct conversion functions 
"""https://github.com/rapidsai/cudf/issues/6418""","""[BUG] Incorrect precision of floating values are being written to csv""",While writing a float64 or float32 column to csv cudf is truncating or just writing upto precision 9 for both float64 and float32,incorrect precision/truncation,accuracy issue,different results ,using proper expression for coversion 
"""https://github.com/pytorch/pytorch/issues/46702""","""torch.multinomial behave unexpectedly on float16 GPU input tensor""",torch.multinomial behave unexpectedly on float16 GPU input tensor when num_samples=1 and replacement=True  1. fails on probability distribution with odd items   2. produce unrepeatable result for large input tensor,misaligned addresses/precision issue,accuracy issue,wrong results ,use correct expressions/ parameters
"""https://github.com/pytorch/pytorch/issues/46391""","""Warnings during compiling: floating-point value does not fit in required integral type""",warning: floating-point value does not fit in required integral type,compiler warnings,correctness bug,error,add floating point return values suport
"""https://github.com/pytorch/pytorch/issues/24213""","""torch.utils.dlpack.from_dlpack causes conversion of CuPy float64 tensor to float 16""","If I pack a float64 or float32 CuPy tensor using to_dlpack and then use it to set the weights of a Pytorch tensor using from_dlpack, the resulting weights are converted to float16.",truncation issue,accuracy issue ,wrong results ,use proper expression
"""https://github.com/huggingface/transformers/issues/7810""","""Metrics calculate error: can only calculate the mean of floating types. Got Bool instead""",,results in bool not float,correctness bug ,wrong results,proper function 
"""https://github.com/tensorflow/tensorflow/issues/43928""","""Using Orthogonal initializer in dense layer with backend set to fp16 gets stuck""",Using Orthogonal kernel initializer in dense layer with backend set to fp16 execution gets stuck during initialization.,no half precision support,correctness bug,program stuck,ignore the half precision 
"""https://github.com/pytorch/pytorch/issues/46238""","""Simple model cannot converge with fp16 precision using torch.cuda.amp""",Simple model cannot converge with fp16 precision using torch.cuda.amp,convergence issue due to versions,accuracy issue ,different results,change versions
"""https://github.com/pytorch/pytorch/issues/45968""","""DDP fp16_compress_hook communication hook increases peak memory """,When using the new fp16_compress_hook in torch 1.7 nightly the peak memory usage increases by an amount equal to the (in memory) size of the gradient tensor,high memory use in backward pass in fp16 ,correctness issue,different results,add corect function with datatype
"""https://github.com/pytorch/pytorch/issues/45724""","""torch.matmul output contains some nan value for large size fp16 tensors in V100 GPU""","If running in Nvidia V100 GPU and with the randomly generated fp16 tensors with size [13269, 8, 22, 64] as input, the torch.matmul output contains some nan value which are not expected",nan results due to cublas issue,special value bugs,different results,fix library issues
"""https://github.com/pytorch/pytorch/issues/20634""","""SyncBN doesn't support fp16 inputs with fp32 parameters""",RuntimeError: expected scalar type Half but found Float error,type issue using mixed precision,correctness issue,error,do manually conversion fp 16 to fp32
"""https://github.com/open-mmlab/mmdetection/issues/4035""","""Test Albu with mask_rcnn_r50_fpn_albu_1x_coco.py failure""",ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(),value error/truth value of one element is ambigious ,correctness issue,error,use another function 
"""https://github.com/PyTorchLightning/pytorch-lightning/issues/4427""","""Gradient accumulation fails with fp16 precision""",RuntimeError: unscale_() has already been called on this optimizer since the last update().,optimizer on unscale(),correctness isssue,error,
"""https://github.com/NVIDIA/TensorRT/issues/816""","""Slow 3D convolution on RTX 2070 (by using -fp16, too)""","3d convolutions take a lot of time, and i think it's really strange, and they don't speed up by switching to fp16.",small precision that does not fit fp16,accuracy issue,slow performance,increase the values
"""https://github.com/thrust/thrust/issues/1268""","""[NV 200636681] Compile Time Failure \""implicit conversion from 'const uint_type' to 'float'\"" with Clang 10.0.0/gpgpu/cuda_a on Ubuntu18.04/x86_64""","Compile Time Failure ""implicit conversion from 'const uint_type' to 'float'"" with Clang 10.0.0/gpgpu/cuda_a","unsupported libray c++ 17 does not support with NCCL, cuda",environment issue,program failure,update support 
"""https://github.com/tensorflow/models/issues/9186""","""TypeError: ('Not JSON Serializable:', tf.float32)""","TypeError: ('Not JSON Serializable:', tf.float32)",type issue,correctness isssue,error,correct the expression
"""https://github.com/rapidsai/cudf/issues/6224""","""[BUG] A column with `inf` values is being treated as \""object\"" dtype instead of \""float\""""","When there are inf values in a column(float dtype), cudf.read_csv is inferring the dtype as ""object"" instead of float",inf issue/ inf is read as floats,special value bugs,wrong results,add inf parsing for floats
"""https://github.com/pytorch/pytorch/issues/44013""","""python value of type 'float' cannot be used as a value in with @torch.jit.script""",RuntimeError: python value of type 'float' cannot be used as a value:,not supporting global values torchscript,correctness issue,error,use as a function parameter/use as a constant 
"""https://github.com/huggingface/transformers/issues/7052""","""TFBert activation layer will be casted into float32 under mixed precision policy""","tensorflow:Layer activation is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx",casting issue when using mixed precision ,accuracy ,bad performance,update versions 
"""https://github.com/cornellius-gp/gpytorch/issues/1284""","""float16 support in gpytorch 1.2?""",doing large-scale exact GP regression with float32s and have run into GPU memory limitations.,memory limitations float 16 does not change memory,accuracy ,perfrmance slow ,use proper casting (hard to fix) 1. Use lazy tensors 
"""https://github.com/apache/incubator-mxnet/issues/16239""","""train_imagenet.py fails with float16 + alexnet """,data type do not match specified type,pred_label.asnumpy() fails,correctness issue ,error,change cuda version 
"""https://github.com/TDAmeritrade/stumpy/issues/194""","""Add Support for float32 Inputs for gpu_stump""",CudaAPIError: [716] Call to cuLaunchKernel results in CUDA_ERROR_MISALIGNED_ADDRESS. STUMPY only supports float64 inputs.,memory issues/precision loss ,accuracy issue ,error on misaligned addresses ,only supports fp64
"""https://github.com/NVIDIA/spark-rapids/issues/837""","""[BUG] Distinct count of floating point values differs with regular spark""",do a COUNT(DISTINCT a) where a is a double or floating point value it will produce an incorrect result if -0.0 and or NaN values are included in it,nan/inf issues/-0/0 issue,special value bugs,incorrect issue,proper implementation of operation 
"""https://github.com/tmabraham/UPIT/issues/12""","""Is to_fp16() Implemented Already?""",The biggest difficulty I'm facing is GPU memory so to_fp16() would improve speed and memory use quite significantly.,mixed precision support not improve speed and memory,accuracy issue ,error,add mixed precision support
"""https://github.com/microsoft/DeepSpeed/issues/426""","""when i  disable fp16 Ã¯Â¼Å’got error: 'lr_this_step' referenced before assignment.""","Notice bert_base.json change fp16 from true to false.then, i got error: 'lr_this_step' referenced before assignment.

second:
when i enable , i found the log warning: OVERFLOW.",overflow in mixed precision in fp16,accuracy issue ,error,wait till automatic adjusment in algo
"""https://github.com/csarofeen/pytorch/issues/362""","""reduction with fp16 cast generates wrong kernel indexing """,reduction with fp16 cast generates wrong kernel indexing ,wrong indexing in kernel due to precision loss when fp16,accuracy issue ,wrong results,add fp16 support 
"""https://github.com/apache/incubator-mxnet/issues/19118""","""[Bug][Numpy] MXNet fp16 initialization bug""", 0-th output has invalid dtype. Expecting 0 got 2 in operator _npi_uniform,implementation/correctnes fp16 casting,correctness issue,error,correct expression 
"""https://github.com/PaddlePaddle/Paddle/issues/27205""","""\""Add bfloat16 data type\"" Ã¥Â¼â€¢Ã¨ÂµÂ·bert fp16 Ã¦Â¨Â¡Ã¥Å¾â€¹Ã¨Â®Â­Ã§Â»Æ’Ã¦Å’â€šÃ¦Å½â€°""",problem is in np.float16(data).view(np.uint16),correctness/implementation,correctness issue,error,use correct expression
"""https://github.com/tensorflow/tensorflow/issues/42392""","""tf-nightly: 'bfloat16' in namespace 'Eigen' does not name a type.""",error: 'bfloat16' in namespace 'Eigen' does not name a type typedef Eigen::bfloat16 bfloat16,type error,correctness issue ,error,update versions 
"""https://github.com/tensorflow/serving/issues/1725""","""Very slow performance on extracting grpc request results using .float_val""",ery slow performance on extracting grpc request results using .float_val,resource exhausted,correctness issue ,slow performance,use correct method
"""https://github.com/pytorch/pytorch/issues/43211""","""torch.norm gives NaN gradient when I input small-value float16 tensor""","The result of a.grad is tensor([nan], device='cuda:0', dtype=torch.float16).",nan issue,special value bugs,wrong output,clamp numbers too small for fp16
"""https://github.com/open-mmlab/mmdetection/issues/3581""","""CORNER NET: AssertionError: RandomCenterCropPad needs the input image of dtype np.float32, please set \""to_float32=True\"" in \""LoadImageFromFile\"" pipeline""","AssertionError: RandomCenterCropPad needs the input image of dtype np.float32, please set ""to_float32=True"" in ""LoadImageFromFile"" pipeline and this error shows while inference. (to_float is True in config)",correctness/ setting ,correctness issue,error,fix the function
"""https://github.com/microsoft/onnxruntime/issues/4147""","""cumsum and topk float16 support""",INVALID_GRAPH : This is an invalid model. Type Error: Type 'tensor(float16)' of input parameter (input) of operator (CumSum) in node (CumSum_1) is invalid.,lack of fp16 support ,correctness issue ,slow/error,add support 
"""https://github.com/gpuweb/gpuweb/issues/1035""","""Bit preserving floating point conversion expressions""", leads to inconsistent handling.set of functions for numerical conversions and one set for bit preserving.,bit preserve/truncating,accuracy issue ,inconsistent ,add bit preserving operation
"""https://github.com/huggingface/transformers/issues/6203""","""Issue with fp16_opt_level default""","RuntimeError: Found param model.model.shared.weight with type torch.cuda.HalfTensor, expected torch.cuda.FloatTensor.",compiler optimization level fails in fp16,correctness issue,error,fix commands
"""https://github.com/tensorflow/tensorflow/issues/41845""","""Tensorflow raises exception in eager mode but works in graph mode \""AttributeError: 'float' object has no attribute '_id'\""""",throws with exception AttributeError: 'float' object has no attribute '_id',type issue ,correctness issue ,error message,use tensor instead float 
"""https://github.com/tensorflow/tensorflow/issues/41783""","""TensorFlow 2.2 using tf.float16 executes only on CPU""","everything works fine, except it runs on CPU instead of GPU","type issue, works only in cpu not gpu",correctness issue ,performance,some operations work only in cpu and not gpu. 
"""https://github.com/tensorflow/tensorflow/issues/40357""","""[TF Lite] TfLiteGpuDelegate Init: CONV_2D: Unsupported data type for float32 tensor""",Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: CONV_2D: Unsupported data type for float32 tensor.,gpu issue,environment issue,performance,int works well in cpu than gpu. Use cpu 
"""https://github.com/tensorflow/models/issues/8878""","""TypeError: Expected int32 passed to parameter 'n' of op 'QueueDequeueManyV2', got 1.0 of type 'float' instead.""","Error: Expected int32, got 1.0 of type 'float' instead.",casting issue,accuracy ,error message,casting batch_size to int work 
"""https://github.com/pytorch/vision/issues/2512""","""Pad() fails on floating point image with TypeError""","TypeError: must be real number, not tuple.",type error ,correctness issue,error,fix the code that uses float 
"""https://github.com/pytorch/pytorch/issues/41779""","""Wrong gradient for torch.norm(x, p=float('inf')) when input tensor has non-unique max values""","Wrong gradient for torch.norm(x, p=float('inf')) when input tensor has non-unique max values",infinity issue ,special value bugs,wrong results,correct the parameter values in the function 
"""https://github.com/pymc-devs/pymc3/issues/2115""","""OPVI does not seem to work in float32""",does not seem to work in float32 ,"accuracy/precision issue, float 32 would cast to float 64",acuracy ,stuck ,use strict_float32
"""https://github.com/pymc-devs/pymc3/issues/1640""","""Cast input data and testvalues to theano.config.floatX""",When theano.config.floatX and the default numpy float dtype do not match (as is the case when you want to use the GPU and set floatX to float32 but numpy is on float64) it causes a lot of problems that require manual casting of all the parameters that get passed in.,casting issue/ need float32 but numpy is in float64,accuracy issue ,failure,needs automatic casting not manual casting
"""https://github.com/mrdoob/three.js/issues/19876""","""NaN in float texture""",NaN in float texture ,nan issue,special value bugs,crash,do nan checks 
"""https://github.com/GPUOpen-Drivers/AMDVLK/issues/94""","""float16 support for Polaris/Baffin ?""",Use of fp16 may cut register pressure in half,half precision support for better improvement ,accuracy issue ,performance,add fp16 for mathematical functions 
"""https://github.com/pytorch/pytorch/issues/41663""","""[Bug] mean of gumbelsoftmax output is nan when fp16""",mean of gumbelsoftmax output is nan when fp16,nan issue,special value bugs,wrong result ,use internal operations larger than the smallest value offp16
"""https://github.com/pytorch/pytorch/issues/41527""","""torch.nn.functional.layer_norm returns nan for fp16 all 0 tensor""","When the input is a torch.float16 tensor and all values are 0, the torch.nn.functional.layer_norm function returns nan",nan issue,special value bugs,wrong result ,small change in value lead to nan (use large epsilon)
"""https://github.com/opencv/opencv/issues/17969""","""YoloV4 error when running fp32""",YoloV4 error when running fp32: CUDNN_STATUS_BAD_PARAM in function 'convolve',wrong parameter problem/cudnn version issue ,environmental issue,error,fix the version 
"""https://github.com/open-mmlab/mmdetection/issues/3315""","""faster_rcnn_r50_fpn training one of my own datasets gets loss_bbox=nan problem""",faster_rcnn_r50_fpn training one of my own datasets gets loss_bbox=nan problem ,nan issue,special value bugs,wrong result ,too small values. Use large values 
"""https://github.com/huggingface/transformers/issues/5651""","""T5 fp16 overflow in forward (T5DenseReluDense)""",T5 fp16 overflow in forward (T5DenseReluDense),overflow leads to nan ,special value bugs,wrong result ,fix the parameters 
"""https://github.com/PyTorchLightning/pytorch-lightning/issues/2673""","""trainer.test after fp16 training with apex""","In the current huggingface examples/seq2seq/finetune.py, trainer.test fails in fp16 mode with torch 1.5.1.",implemenation issue/optimizations in fp16 fails,correctness issue ,fail/error,upgrade versions 
"""https://github.com/PyTorchLightning/pytorch-lightning/issues/2564""","""Logging loss is extremely large when training with fp16""","Logging loss is extremely large(e.g. 10000) when training with fp16, but I find that the loss in tfboard is quite normal(e.g. 1.0).",accuracy-large loss/precision issue ,accuracy bug,wrong result ,fix the loss function for fp16
"""https://github.com/NVIDIA/TensorRT/issues/726""","""BERT demo --fp16 build error: ERROR: (Unnamed Layer* 2) [PluginV2DynamicExt]: could not find any supported formats consistent with input/output data types""",BERT demo --fp16 build error,program fails with --fp16,correctness issue,error,fix function that uses fp16
"""https://github.com/tensorflow/tensorflow/issues/40742""","""compilation of rule '//tensorflow/python:bfloat16_lib' failed when building TF2.2 from source""",compilation of rule '//tensorflow/python:bfloat16_lib' failed,compilation issue,correctness issue,build failure,fix the support
"""https://github.com/tensorflow/tensorflow/issues/40688""","""C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed""",C++ compilation of rule '//tensorflow/python:bfloat16_lib,compilation issue/,correctness issue,build failure,fix bfloat16 support
"""https://github.com/tensorflow/tensorflow/issues/40308""","""TypeError: Expected int64, got 1e-07 of type 'float' instead : FasterRCNN tensorflow 2.x""","TypeError: Expected int64, got 1e-07 of type 'float' instead.",type error int64 gives a float value,correctness issue ,error,fix the function parameter
"""https://github.com/tensorflow/tensorflow/issues/40167""","""GPU delegate not as accurate as NNAPI reference  on 16float models on Style Transfer example. tensorflow-lite""",GPU delegate not as accurate as NNAPI reference on 16float models on Style Transfer example. tensorflow-lite,mathematical operations differ in fp16,accuracy issue ,wrong result,use large values
"""https://github.com/pytorch/pytorch/issues/40580""","""Multiply a bfloat16 tensor with a double tensor leads to RuntimeError""",RuntimeError: common_dtype_ != ScalarType:Multiply a bfloat16 tensor with a double tensor leads to RuntimeError ,type issue,correctness issue ,error,only supports bfloat16 types others fail 
"""https://github.com/gfx-rs/wgpu/issues/362""","""copy_buffer_to_buffer with size 0 causes floating point exception on Metal""",copy_buffer_to_buffer with size 0 causes floating point exception on Metal,floating point exception/divide by zero ,correctness issue ,error,check for 0 division 
"""https://github.com/facebookresearch/PyTorch-BigGraph/issues/147""","""RuntimeError: Function AddBackward0 returned an invalid gradient at index 1 - expected type TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false) but got TensorOptions(dtype=float, device=cuda:0, layout=Strided, requires_grad=false)""",,correctness issue/tensors are in different devices ,correctness issue ,error,assign the tensors to the same device 
"""https://github.com/deepset-ai/FARM/issues/395""","""Regression label float to int conversion bug""","Silent error, all my regression labels are being converted to longs.Expected behavior
Regression labels should be retained as floats.",casting issue using floats casts to longs ,accuracy issue ,result,fix the casting 
"""https://github.com/tensorflow/addons/issues/1920""","""LookAhead + RAdam + mixed_fp16 = apply_gradients() got an unexpected keyword argument 'experimental_aggregate_gradients'""",When i set global mixed precision policy tf.keras.mixed_precision.experimental.set_policy('mixed_float16') meta-optimizer LookAhead + RAdam raises error,unexpected error when using mixed precision ,correctness issue,error,fix missing arguments 
"""https://github.com/huggingface/transformers/issues/5300""","""T5ForConditionalGeneration fp16 nan loss""",T5ForConditionalGeneration fp16 nan loss,nan occurs when using fp16 becomes inf ,special value bugs,wrong results,solve optimization bugs 
"""https://github.com/PaddlePaddle/Paddle/issues/17397""","""Training with fp16 fails due to not registered operator.""","ValueError: Operator ""allreduce"" has not been registered.Disabling fp16: --fp16=False results in correct training both on GPU and CPU",not registered operator for fp16,correctness issue ,error,disable fp16
"""https://github.com/NVIDIA/TensorRT/issues/585""","""int8 mode only 5-10% faster than fp16""",int8 mode only 5-10% faster than fp16 ,int8 does not offer significant performance compared to fp16,accuracy issue ,slow performance,int 8 does not work on all kernels 
"""https://github.com/tensorflow/tensorflow/issues/39985""","""Conv3D operations are not using tensor cores with mixed float16 policy""",When using Conv3D layers and a mixed float16 policy the Conv3D layers do not use tensor cores.Using the same settings for a Conv2D layer does result in the Conv2D layers using the tensor cores.,mixed precision does not use tensor cores in cudnn version ,environmental issue ,slow performance,update library versions 
"""https://github.com/tensorflow/tensorflow/issues/39287""","""Using tf.nn.softmax with tensor of dtype `int321 throws exception - works fine with float32""","Error is thrown when a tensor is used in the tf.nn.softmax with dtype of int32, as seen below,",type issue promoting int to float issue ,accuracy issue ,wrong results,tf does not support int32 change the type 
"""https://github.com/tensorflow/models/issues/8576""","""object of type <class 'numpy.float64'> cannot be safely interpreted as an integer""",TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.,type issue unsupported float index in numpy ,environmental issue ,error,upgrade/downgrade numpy version 
"""https://github.com/rapidsai/cudf/issues/5098""","""[BUG] Casting floating-point to string produces incorrect value for negative zero""",Casting the floating-point values -0.0f and -0.0d to string produces 0.0 instead of -0.0.,(-0 issue,special value bugs,incorrect results,check for -0 correctly 
"""https://github.com/pyvista/pyvista/issues/713""","""Issue with SetSpacing in UniformGrid.points, not stable in case of float spacing""",UniformGrid.points setter not stable - need to deprecate,type error not stable ,correctness issue ,error,use a different function
"""https://github.com/pytorch/pytorch/issues/38018""","""median with float64, lot of nans, and dim=1 returns random results in CUDA""","median with float64, lot of nans, and dim=1 returns random results in CUDA",nan issue mising nan check ,special value bugs,random values,check for two nans
"""https://github.com/onnx/onnx/issues/2801""","""float16 support for cumsum and topk""","""float16"" type has not been supported in onnx runtime",no fp16 support ,correctness bug ,incorrect results,add the support 
"""https://github.com/gpuweb/gpuweb/issues/775""","""scientific notation is not permitted in float literals""",scientific notation is not permitted in float literals ,accuracy-scientific notation problem not valid number ,accuracy issue ,error,change expression 
"""https://github.com/google/automl/issues/351""","""New mixed_float16 results by a very slow training""", tested the new mixed_float16 : it consumes less memory on the GPU (half ) but finally the training is very very slow now,correctness issue mixed precision is slow ,correctness bug,slow performance,update tensorflow version 
"""https://github.com/glotzerlab/hoomd-blue/issues/641""","""precision of uniform floating point numbers""","RandomNumbers.h we currently generate 64bit unsigned longs and use the max value to scale to a uniform double. 2^64-1, however, is not exactly representable as a double, and therefore we're loosing precision. In practice that means that the generated float is not exactly uniform, it only is up to the number of mantissa bits (53",accuracy-precision loosing ,accuracy issue ,error,use large numbers instead of small epsilons 
"""https://github.com/PyTorchLightning/pytorch-lightning/issues/1876""","""Load batches as float16?""","The output I get seems to indicate that the batches are stored as fp32 on the GPU, consistent with high memory usage:",less memory fp16 uses high memory ,correctness issue ,performance,some parameters should be converted to fp16
"""https://github.com/BlazingDB/blazingsql/issues/668""","""[BUG] Union All floats fails with datatype mismatch""",Union All floats fails with datatype mismatch ,correctness issue data type mismatch ,correctness issue ,error,use proper concatenation of datattype 
"""https://github.com/huggingface/transformers/issues/4586""","""T5Model in fp16 still yield nan with more complex examples""",T5Model in fp16 still yield nan with more complex examples,nan raised due to inf ,special value bugs,different results,use large values 
"""https://github.com/huggingface/transformers/issues/4287""","""T5 fp16 forward yields nan""",T5 fp16 forward yields nan ,nan due to small values ,special value bugs,different results,use floats instead fp16 
"""https://github.com/tensorflow/tensorflow/issues/38850""","""Mixed Precision + Gaussian Noise throws data type error float16 / float 32""",TypeError: Input 'y' of 'AddV2' Op has type float32 that does not match type float16 of argument 'x'.,type issue mixed precision fails ,correctness issue ,error,fixed expressions that use cases (commits) 
"""https://github.com/tensorflow/tensorflow/issues/38381""","""Casting from float32 to uint8 results in wrong value despite being from 0 to 255""",Casting from float32 to uint8 results in wrong value despite being from 0 to 255,casting issue,accuracy issue ,wrong results,proper casting 
"""https://github.com/tensorflow/serving/issues/1589""","""Performance issue with tf serving QPS and client latency on float16 NWHC data""",same model with different data types will produce dramatically different QPS results,different data types produce different results and slow/fp16 is not included ,correctness issue ,bad performance,add fp16 
"""https://github.com/pytorch/xla/issues/1955""","""Mixed precision training slower than float32""",Mixed precision training slower than float32 ,implementation/correctness issue/ setting high precision flags,correctness issue ,slow performance,fix the expression 
"""https://github.com/pytorch/pytorch/issues/36807""","""Regression with explicit type conversion from float to uint8 on gpu devices.""",result is wrong,explicit type conversion from float to int ,correctness issue ,wrong results,do cast testing to catch issues
"""https://github.com/microsoft/onnxruntime/issues/3736""","""Trouble running model with float64 input""",Type Error: Type parameter (T) bound to different types (tensor(double) and tensor(float) in node (lstm_3).',incorrect type conversion ,correctness issue ,error,convert all weights and biases to same type 
"""https://github.com/microsoft/onnxruntime/issues/3735""","""Loading float16 model fails""",Loading float16 model fails,no flaot16 support ,correctness issue ,error,use float32
"""https://github.com/gpuweb/gpuweb/issues/709""","""support C99 hex float literals to accurately capture float values""",,no support for hex float literals ,accuracy issue ,wrong results ,add hex float support 
"""https://github.com/awslabs/djl/issues/49""","""Mx Net Engine truncates float values to integers on systems with a German locale""",Operations on MxNDArray that take a single Number argument truncate the arguments decimal places which leads to erroneous calculation results.,truncation values for all math operations ,accuracy issue ,incorrect results,
"""https://github.com/ROCmSoftwarePlatform/MIOpen/issues/96""","""Segmentation fault at miopenFindConvolutionBackwardWeightsAlgorithm for half float""",The program crashes at line err = miopenFindConvolutionBackwardWeightsAlgorithm,compiler issue/gpu issue for OpenCL ,correcntness issue ,error,fix the comiler issue 
"""https://github.com/pytorch/xla/issues/1936""","""fp16 (not bf16) support""","tried to test the performance with fp16, and found that current implementation does not support it. I see that bf16 is supported. However, unfortunately, many GPUs do not support it.",correctness issue no support for fp16 ,correctness issue ,error,add fp16 support 
"""https://github.com/huggingface/transformers/issues/3831""","""AlbertModel output is not fp16""","turned the model to fp16 with apex, the hidden representation output is not half tensor ",compiler optimization issue ,correctness issue ,error,do not use type conversions in Opt level 1
"""https://github.com/tensorflow/tensorflow/issues/34782""","""[tf.keras] Mixed precision policy \""mixed_bfloat16\"" not supported in Keras compile""","Mixed precision policy ""mixed_bfloat16"" not supported in Keras compile",no mixed_bfloat support ,correctness issue ,error,up tf-nightly version 
"""https://github.com/tensorflow/addons/issues/1282""","""ValueError for RSquare metric - requested dtype float32 for Tensor with dtype float64""",conversion to float32 fails,value error type cast,correctness issue ,error,use self.dtype fr floats 
"""https://github.com/kovidgoyal/kitty/issues/2446""","""ValueError from pre-render on font resizeÃ¢â‚¬â€cannot convert float NaN to integer""","The floating point is blowing up somewhere, so I checked my config for any rendering-related values set to zero (in case this was a div-by-zero),",nan issue on input ,special value bugs,error,fix the values on variables
"""https://github.com/facebookresearch/faiss/issues/860""","""GpuIndexIVFPQ's quantizer can't use float16""","This gpu index can be successfully trained, but it crashes when adding vectors",float16 vectors fail,correctness issue ,error,implement float16 quantizer 
"""https://github.com/UIUC-PPL/charm/issues/2754""","""Running with fewer PEs that GPUs fails with floating point exception""",floating point exception,floating point exception pn gpu-gpu communication ,correctness issue ,error,have values greater than number of GPUs fpr gpu-gpu communication 
"""https://github.com/pytorch/vision/issues/1934""","""torchvision.models.detection.fasterrcnn_resnet50_fpn has loss_rpn_box_reg exploding to nan after evaluation""","The behavior is similar on the full dataset, with loss_rpn_box_reg apparently exploding to nan shortly after the first epoch.",nan produce due to misuse ,special value bugs,wrong output,correct the method
"""https://github.com/NVIDIA/TensorRT/issues/420""","""TRT7 onnx parser error when building fp16 engine""",failed when building args was set to fp16 mode.,overflow weights are out of range ,acuracy issue ,error,use the setPrecision on each of the potential fp16 layers along with the STRICT_TYPES flag to search for the bad layer
"""https://github.com/tensorflow/tensorflow/issues/37123""","""Unsupported object type float""",InternalError: Unsupported object type float,broken values in DF,correctness bugs,error,Checking the dataframe with np.unique(df[column] and df[df.isnan()]
"""https://github.com/tensorflow/tensorflow/issues/36696""","""UpSampling2D doesn't support bfloat16 in TF 2.1""","TypeError: Value passed to parameter 'images' has DataType bfloat16 not in list of allowed values: int8, uint8, int16, uint16, int32, int64, float16, float32, float64",type  issue not supports bfloat16,correctness bug ,error,fix in nightly build 
"""https://github.com/tensorflow/models/issues/2961""","""InvalidArgumentError: TypeError: 'numpy.float64' object cannot be interpreted as an integer""",TypeError: 'numpy.float64' object cannot be interpreted as an integer,type error numpy fp64 does not support tf version ,environment issue ,error,downgrade numpy version 
"""https://github.com/tensorflow/models/issues/2841""","""random_pad_image throwing a \""type int32 that does not match type float32\"" error""",TypeError: Input 'y' of 'Maximum' Op has type int32 that does not match type float32 of argument 'x',type issue during implementation of code,correctness bug ,error,fix the expression 
"""https://github.com/pytorch/pytorch/issues/33651""","""torch.tril_indices returns a float tensor on cpu on master""","torch.tril_indices returns a torch.float32 tensor, but it should return an torch.int64 tensor",build issue returns fp32 instead int ,correctness issue ,error,specify dtype 
"""https://github.com/catboost/catboost/issues/1177""","""CatBoost predict differently -> if float values are rounded to less than 9 decimals when training""",CATBOOST predicts differently -> if float values are rounded to less than 9 decimals when training.,acuracy in rounding off,accuracy issue ,results,round off to 8 decimeals instead 9 
"""https://github.com/GPflow/GPflow/issues/1244""","""GPFlow-2.0 - issue with default_float and mean variance""",GPFlow-2.0 - issue with default_float and likelihood variance,corrrectness/accuracy fails in fp64 and works with fp32,accuracy ,error,fix the expression 
"""https://github.com/pytorch/pytorch/issues/32750""","""torch.prod with internal upcasting (fp16 input, dtype=torch.float32 output) produces garbage""","FP16 input, FP32 output produces garbage data (zero-ish)",incorrect function implementation ,correctness issue ,garbage output,fix the function parameter
"""https://github.com/OpenNMT/OpenNMT-py/issues/1724""","""fp16 zero division error on multiple GPUs""",ZeroDivisionError: division by zero,mixed precision leads to zero division fp16,correctness issue ,error,restrict to fp32 only
"""https://github.com/KhronosGroup/glslang/issues/2076""","""Extension not supported: GL_NV_gpu_shader5, GL_NV_shader_atomic_fp16_vector""","lose too much precision and converting to uints/ulongs means the values can't be added in the same manner. Float atomics also use GL_NV_shader_atomic_float which uses GL_NV_gpu_shader5, which the compiler doesn't want to enable (",precision loss on atomic floats ,accuracy issue ,error,use non atomic floats 
"""https://github.com/tensorflow/tensorflow/issues/36358""","""TypeError: '>' not supported between instances of 'Nonetype' and 'float'""","Briefly it says that logs.get('acc') is Nonetype and 0.99 is float so, '>' this cannot compare. ",type error nontype vs floats cannot compare >,correctness issue ,error,replace code 
"""https://github.com/tensorflow/tensorflow/issues/35883""","""AlphaDropout & mixed_float16 - Op has type float32 that does not match type float16""",TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.,mixed float16 does not match with float 32,correctness issue ,error,try with float32
"""https://github.com/tensorflow/tensorflow/issues/35817""","""LayerNormalization dtype issues with mixed_precision.Policy('mixed_float16')""",TypeError: Value passed to parameter 'scale' has DataType float16 not in list of allowed values: float32,type error float116 is not listed,correctness issue ,error,update tf-nightly version
"""https://github.com/tensorflow/tensorflow/issues/35553""","""set_floatx('float16') slow to build/compile""",Take a long time to build/compile a seq2seq model when use set_floatx('float16') instead float32 (default),numerical instability on float16 ,correctness issue ,slow performance,use mixed precision instead float 16
"""https://github.com/schyun9212/maskrcnn-benchmark/issues/10""","""INVALID_GRAPH : This is an invalid model. Type Error: Type 'tensor(float)' of input parameter (44) of operator (Equal) in node () is invalid.""",error was caused there was an opearation to compare Float tensor vs Constant.,operation comparison issue ,correctness issue ,error,fix the expression using the operations
"""https://github.com/microsoft/nni/issues/1589""","""ValueError: Out of range float values are not JSON compliant""",ValueError: Out of range float values are not JSON compliant,overflow leads to nan issue ,special value bugs,error,allow nan data metrics
"""https://github.com/dmlc/xgboost/issues/5226""","""Unit test failing due to floating-point fluctuation""",Unit test failing due to floating-point fluctuation,unit test fails in floats fluctuaion ,accuracy issue ,different results ,prevents weight from getting close to 0
"""https://github.com/diku-dk/futhark/issues/839""","""Add break on floating-point exceptions in the repl""","It would be helpful to have the repl automatically break execution when encountering floating-point exceptions like divide by zero, nan, etc.",nan issue no break points ,special value bugs,crash,add breakpoints on nan
"""https://github.com/PaddlePaddle/PaddleDetection/issues/180""","""What's expected performance float32/float16?""","I get around 4 images per second using fp32, and when I switch to fp16 (by adding --fp16) the performance does not increase, it's still around 4 images per second.",smallter batch sizes are slow inn fp16,correctness issue ,slow performance,change the batch sizes to fpn
"""https://github.com/under-Peter/OMEinsum.jl/issues/79""","""error with high precision numbers on GPU""",error with high precision numbers on GPU,high precision numbers,accuracy issue ,error,fix the dispatch 
"""https://github.com/tensorflow/tensorflow/issues/35307""","""I got nan value when I to predict in cpu,this model that I trained it in gpu""","when using a trained pix2pix model to predict in cpu ,but I got a nan value .if I use the model that trained in CPU，its work right",nan output in gpu and not in cpu,special value bugs,inccorect results,update versions in tf
"""https://github.com/tensorflow/tensorflow/issues/35309""","""tf.math.sigmoid precision issues on GPU""",We compared TensorFlow versions 2.1.0.dev20191203 and 2.1.0.dev20191219 and found some precision differences when using tf.math.sigmoid,precision differences when using sigmoid ,accuracy issue,different results,change in tf version 
"""https://github.com/facebookresearch/meshrcnn/issues/16""","""GPU utilization, latency during inference and model accuracy""","I ran the evaluation both with the shared meshrcnn_R50.pth and the model I trained, and it seems that the accuracy of the model is 10% worse using my model",accuracy of the model is 10% differ,accuracy issue ,different results ,"modified several other parameters in the solver such as the # iterations, step size, warm up iterations"
"""https://github.com/uber/ludwig/issues/663""","""Difference in accuracy between tensorflow-GPU and tensorflow-CPU with 10x kfold""",With an identical dataset and using 10x kfolds there are significant differences in the mean kfold accuracy.,missing lstm configure,accuracy issue ,different results,change the configuration
"""https://github.com/lucidrains/reformer-pytorch/issues/36""","""torch.nn.DataParallel causes strange GPU memory overflow""",,gpu memory overflow,correctness issue ,slow performance,use single gpu
"""https://github.com/tensorpack/tensorpack/issues/1421""","""total_loss becomes nan after some time during training with two GPU's. No issues with single GPU.""",total_loss resulting in nan after sometime during training using two GPU's,nan outputs when multiple gpu training ,special value bugs,incorrect results,dataset works well in one gpu
"""https://github.com/tensorflow/tensorflow/issues/30056""","""multi-gpu training: tf.compat.v1.scatter_sub() operation throws exception""",multi-gpu training: tf.compat.v1.scatter_sub() operation throws exception,operation issue n scatter_sub throwns exception,correctness issue,error/exception,change the script 
"""https://github.com/explosion/spaCy/issues/4916""","""Spacy 2.2.3 gpu prediction gives less accurate result than spacy 2.0.18 cpu""",that older spacy gives much better prediction result,installayion environment corrupted lead to accuracy issue ,environmental issue,wrong numbers,install python completely 
"""https://github.com/choderalab/perses/issues/657""","""Change endstate validation test to use GPU in double precision mode""",pdate the endstate validation tests to use the GPU platform in double precision mode.,gpu support/ double precision support,correctness issue ,slow performance,support doubles with cuda
"""https://github.com/apache/incubator-mxnet/issues/17792""","""Softmax raises exception for zero-size tensor on GPU""",,exception on zero size inputs ,correctness issue ,error,"fix the softmax, logsoftmax methods"
"""https://github.com/dmlc/xgboost/issues/5632""","""XGBoost 1.1.0 SNAPSHOT gpu_hist still numerically unstable""",gpu_hist still numerically unstable,numerically unstable method,correctness issue ,different values,data partitioning or updating the cuda version
"""https://github.com/ClangBuiltLinux/linux/issues/1017""","""-Winteger-overflow in drivers/gpu/drm/amd/amdgpu/amdgpu_device.c""", overflow in expression; result is -294967296 with type 'long',integer overflow,accuracy issue ,error,fixing the int 
"""https://github.com/tensorflow/tensorflow/issues/40805""","""LSTM loss and accuracy values differ greatly between GPU and CPU implementation""",LSTM model the results differ by an order of magnitude (in the log sense) between GPU and CPU implementations,floating point error different in cpu and gpu ,accuracy issue ,different values,fix the loss function
"""https://github.com/google/jax/issues/3270""","""ops.index_add double precision performance on GPUs""",double precision performance of jax.ops.index_add is far slower (maybe around 400x times) than single precision,fp64 atomic add issue,correctness issue ,slow performance,fix the atomic add method 
"""https://github.com/tensorflow/models/issues/7661""","""Dose the data division for multi-gpu destruct the accuracy?""","Data division for multi-gpu after tf1.11 seems to have the same shape of data across all gpus, which will result in a bigger variance of loss between different steps",data dicision cause accuracy issues in variance ,accuracy issue ,different results,lower tf version
"""https://github.com/tensorflow/addons/issues/1942""","""Failed GPU optimizer test with mixed precision""",Failed GPU optimizer test with mixed precision,test fail in mixed precision,correctness issue ,error ,adding gradient support 
"""https://github.com/livepeer/verification-classifier/issues/98""","""Test verifier accuracy when renditions transcoded by a GPU""",he accuracy is 20% lower for GPU codec renditions.,bitrate-adjusted renditions cause accuracy in gpu,acuracy issue ,different results,fix the implementation
"""https://github.com/tensorflow/tensorflow/issues/41657""","""NaN loss and accuracy when using MirroredStrategy on multiple GPUs (ROCm)""",NaN loss and accuracy when using MirroredStrategy on multiple GPUs ,nan loss and accuracy ,special value bugs,performance issue,use 1 gpu
"""https://github.com/PointCloudLibrary/pcl/issues/3583""","""Inaccurate results with gpu octree search example""",Getting inaccurate results from the octree radius,Radius search seems to just find an irregular block of points around the query points,correctness issue ,innacurate results,radius search takes only single float 
"""https://github.com/AlexeyAB/darknet/issues/6400""","""How to train YOLOv3_tiny_3l on g4dn.12xlarge 4 GPU (NVIDIA T4) -> *** buffer overflow detected ***""",buffer overflow detected,overflow when using multiple gpus with low values ,accuracy issue ,error ,fix the implementation of anchor
"""https://github.com/pytorch/pytorch/issues/44350""","""`mean` and `var` overflow on CPU and GPU""",mean and var overflow on CPU and GPU for float and half. ,overflow in mean and var func,accuracy issue ,results,support for higher precisions
"""https://github.com/MouseLand/Kilosort2/issues/231""","""learnTemplates: Error in median() using gpuArray/nan when printing status of batch with 0 spikes""",Error using gpuArray/nan. An unexpected error occurred trying to launch a kernel,produce nan,special value bugs,error,ignore values with 0 
"""https://github.com/PyTorchLightning/pytorch-lightning/issues/3382""","""'precision=16' doesn't change GPU memory consumption""",'precision=16' doesn't change GPU memory consumption,fp16 doesn't change,correctness issue ,slow performance ,ignore pytorch autocast that doesn't use 16-bit floats 
"""https://github.com/CliMA/Oceananigans.jl/issues/828""","""Obscure GPU error when time stepping a model with Julia 1.5 and Oceananigans v0.33.0"""," Warning: Performing scalar operations on GPU arrays: This is very slow, consider disallowing these operations with `allowscalar(false)",float64 fails ,correctness issue ,slow performance,fix the method specified with proper type conversions 
"""https://github.com/CliMA/Oceananigans.jl/issues/1010""","""Cannot use `Forcing`s with `field_dependencies` on GPU with Oceananigans v0.39.0""",,gpu test fails with type issue ,correctness issue ,error,add support tuple{} type
"""https://github.com/tensorflow/tensorflow/issues/44990""","""tf-gpu 2.3.1 get initial low accuracy compare to tf-gpu 2.1""",much lower accuracy 0.35 to begin with comparing 0.7,accuracy difference in two versions,environmental issue ,different results,updates version fixed the previious version issue 
"""https://github.com/tensorflow/tensorflow/issues/40072""","""tf.nn.relu on nan inputs returns zeros on GPU""",The behavior of tf.nn.relu when fed with nan-valued inputs is inconsistent between GPU and CPU,nan input outputs 0,special value bugs,results,fixing nan issue by updating tf version
"""https://github.com/pytorch/pytorch/issues/1810""","""\""nan\"" behaves differently in CPU and GPU""","nan"" behaves differently in CPU and GPU",nan behaves undefined ,special value bugs,cpu gpu results,stop using crazy large negative number s
"""https://github.com/openmm/openmm/issues/2930""","""Low CustomNonbondedForce calculation accuracy with GPU platforms"""," accuracy of force calculation with CUDA and OpenCL platforms is low compared to CPU and Reference platforms, with both single and double precision.","accuracy issue in cuda, opencl, versions compared to cpu",accuracy issue ,compare results,higher the precision
"""https://github.com/dmlc/xgboost/issues/6228""","""gpu_hist integer overflows and OOM issues""",Thrust copy_if has an integer overflow when n_rows*n_cols > 2^31,overflow leads to memory issues,correctness issue ,performance issue,limit the partition 
https://github.com/rapidsai/cudf/issues/9672,[BUG] row range on window operations can overflow #9672,overflow issue ,accuracy issue ,accuracy issue ,wrong results ,fix bounds 
https://github.com/rapidsai/cudf/issues/9597,[BUG] Cast Decimal64 to Decimal128 is really slow #9597,cast issue ,accuracy issue ,accuracy issue ,performance issue ,add support 
https://github.com/rapidsai/cudf/issues/9065,[BUG] cudaErrorInvalidValue when creating cudf.Series from float16 CuPy Series #9065,"error when creating a Series from float16 CuPy objects, ",casting issue ,accuracy issue ,error message,fix cast 
https://github.com/rapidsai/cudf/issues/9014,[BUG] Wrong decimal values after changing data type #9014,wrong value when we change the decimal data type using Decimal64Dtype.,truncate issue ,accuracy issue ,wrong values ,convert to decimal first then round 
https://github.com/rapidsai/cudf/issues/7689,[BUG] Libcudf unary cast returns unexpected results when casting between decimal and int types #7689,libcudf unary cast function sometimes returns unexpected values when casting between int types other than int64 and decimal,casting issue ,accuracy issue ,wrong results ,add typecasting 
https://github.com/rapidsai/cudf/issues/7488,"[BUG] Problems converting String dtype Series with ""nan"" to Float (ValueError) #7488",casting issue in cudf ,casting issue ,accuracy issue ,crash ,add typecasting for string Nan 
https://github.com/rapidsai/cudf/issues/7402,[BUG] std incorrectly calculated in dask describe calls for specific dataframe values #7402,NaN issue ,speical value issue ,speical value issue ,wrong values ,improve stbility in methods
https://github.com/rapidsai/cudf/issues/7284,[BUG] OverflowError when trying to replace inf values in an integer column #7284,"trying to replace all inf values via replace API, when we have a mix of int & float columns we are letting an OverFlowError propagate which shouldn't be happening.",overflow error ,accuracy issue ,wrong values ,handle overflow issues with replace
https://github.com/rapidsai/cudf/issues/7113,[BUG] read_parquet reads incorrect values when requested to read a portion of a file #7113,read_parquet reads incorrect values when skiprows and num_rows are set.,correctness issue ,not handling nulls ,wrong values ,fix the method 
https://github.com/rapidsai/cudf/issues/7056,[BUG] one_hot_encoding is not handling correctly for cases when data has nan values #7056,"When the data has a nan & <NA>, one_hot_encoding is classifying nan as a None",Nan issue ,special value bugs ,wrong output ,handle NaN values 
https://github.com/rapidsai/cuml/issues/4273,[BUG]DBSCAN.fit on empty array raise floating point exception and terminate python #4273,If the input of the DBSCAN.fit is an empty array the following error is appearing and Python terminates,correctness issue ,correctness issue ,exception ,Throw an explicit excpetion if the input array is empty in DBSCAN.fit
https://github.com/rapidsai/cuml/issues/3910,[BUG] RF : regression in GPU predict accuracy compared to CPU predict and scikit-learn predict #3910,cuml predictions on GPU (FIL) seems to be less accurate than CPU predictions,,accuracy issue ,wrong results ,fix the algorithm 
https://github.com/rapidsai/cuml/issues/3567,[BUG] Confusion matrix should convert dtype as necessary #3567,confusion_matrix should automatically convert dtypes as appropriate in order to avoid failing,type issue ,correctness issue ,error ,fix type conversions 
https://github.com/rapidsai/cuml/issues/3305,[BUG] Negative R-Squared with Nightly (0.17) #3305,sklearn and cuml have different values ,,correctness issue ,wrong values ,fix cuml method 
https://github.com/rapidsai/cugraph/issues/1330,[BUG] PageRank Values Miscalculated with Float Weights #1330,pagerank ethod return wrong results ,correctness issue ,,wrong results ,fix the pagerank method 
https://github.com/NVIDIA/cutlass/issues/144,LinearCombinationRelu epilogue has different behaviour between compute 7.0 and compute 7.5 #144,"compute_70 feature set, but with compute_75 floating point numbers are rounded down to the nearest integer value",nvcc issue ,environmental issue ,wrong results,fix envrionment 
https://github.com/NVIDIA/cutlass/issues/124,minimum() operator in CUTLASS? #124,operator fits in the bigger picture.,correctness issue ,implementation issue ,error ,fix implementation 
https://github.com/NVIDIA/cutlass/issues/106,Performance on tensor core #106,fp16 tensor core performance on Tesla T4 GPU.,environmental issue ,environmental issue ,bad performance ,change version or gpus 
https://github.com/NVIDIA/cub/issues/394,Unable to build with -D__CUDA_NO_HALF_CONVERSIONS__ #394,"-D__CUDA_NO_HALF_CONVERSIONS__ is required for PyTorch, because PyTorch has its own half type",correctness issue ,correctness issue ,error ,add half type support 
https://github.com/JuliaGPU/CUDA.jl/issues/962,Integer division error for the product of sparse times empty matrices #962,The product of a sparse matrix times a zero-sized matrix produces an error.,correctness issue ,correctness issue ,error ,fix the method 
"""https://github.com/cupy/cupy/issues/2904""","""cupy.einsum is very slow for elementwise operations""",,einsum issue when using specific operations ,correctness issue ,slow perfrmance,"use cutensorContraction, a tensor contraction routine in cuTENSOR, instead of matmul as a backend for cupy.einsum."
"""https://github.com/cupy/cupy/issues/3302""","""Element-wise power of ndarray is not accurate""",,"power operator issue, numerical precision issue in last digit ",accuracy issue,difference results,change the algoithm 
"""https://github.com/cupy/cupy/issues/3274""","""CUSOLVERError: CUSOLVER_STATUS_INVALID_VALUE""",,int overflow in cusolver library ,correctness issue ,error,fix the library 
"""https://github.com/cupy/cupy/issues/1912""","""cupy.cuda.memory.OutOfMemoryError: out of memory to allocate""",,OOM memory when using fp64,correctness issue ,error,use reduction kernel 
"""https://github.com/cupy/cupy/issues/2780""","""`TypeError` when using `cupy.nanstd` and `cupy.nanvar`""",,type error-mismatched datatypes,correctness issue ,error,fix datatypes 
"""https://github.com/cupy/cupy/issues/3701""","""ValueError when loading .npy using np.load()""",,"not supported datatypes, value error in cupy not with numpy",correctness issue ,error,use datatypes supported by gpu 
"""https://github.com/cupy/cupy/issues/3652""","""NaN when using big-endian arrays""",,nan issue in big endian arrays,special value bug,different results,use little endian arrays
"""https://github.com/cupy/cupy/issues/3602""","""On how to enable users to use TF32 in CuPy""",,unable datatypes tf32,correctness issue ,slow perforamnce,use complex32 datattypes
"""https://github.com/cupy/cupy/issues/3568""","""cupy.percentile only calculates integer percentiles when the input data is an integer.""",,method issue casting issue,accuracy issue ,wrong results,Fix cupy.percentile type assignment in asarray
"""https://github.com/cupy/cupy/issues/2360""","""Array indexing of sparse matrices""",,unsupported indexing in cupy,correctness issue ,error,add support 
"""https://github.com/cupy/cupy/issues/4009""","""Possible typo (\""dype\"" instead of \""dtype\"") in cufft.pyx""",,attribute error type error ,correctness issue ,error, call directly to cupy cupy.cuda.cufft
"""https://github.com/cupy/cupy/issues/3909""","""Passing cupy functions into cupyx.scipy.ndimage.filters.generic_filter causes a TypeError""",,type error/bad function ,correctness issue ,error,call rawkernel or reductionkernel 
"""https://github.com/cupy/cupy/issues/4122""","""cp.exp(0) should return 1.0 not array(1.0)""",,function error exp returns an array,corretness issue ,different results,fix scalar issue 
"""https://github.com/cupy/cupy/issues/4121""","""Incorrect c type used for 64 bit integer (effects sort, unique and presumably various other functions)""",,64 bit int type issue ,correctness issue ,different results,fix 64 bit int 
"""https://github.com/cupy/cupy/issues/4072""","""cupyx.scipy.sparse missing the @ operator, i.e.  __matmul__ and __rmatmul__""",,missing operator issue,correctness bug,error,add operator
"""https://github.com/cupy/cupy/issues/2559""","""Single-precision `sum()` over certain axes sometimes deviates from NumPy's outcome""",,insufficient numerical precision,accuracy issue ,values deviate,change functions or improve precision
"""https://github.com/cupy/cupy/issues/4354""","""suprising behavior of cupy.array on numpy views with base array of a different dtype""",,missing compatibility of array,correctness issue ,output,need a check on the input object in cp.array 
"""https://github.com/cupy/cupy/issues/4223""","""OverflowError: value too large to convert to int""",,overflowtoo large for conversion,accuracy issue ,error,fix type support 
https://github.com/cupy/cupy/issues/6047,cupyx.scipy.signal.convolve2d: integer overflow when using mixed dtypes #6047,,int overflow occurs in cupy not in scipy,accuracy issue ,different results,use upcasting to fix
https://github.com/cupy/cupy/issues/5989,cupyx.scipy.signal.convolve2d yields a JitifyException: Runtime compilation #5989,,(complex128)casting issue/ correct implemetation,correctness issue ,error ,add casting properly 
https://github.com/cupy/cupy/issues/5848,Indexing with assignment between broadcastable arrays is inconsistent with NumPy #5848,,"cupy.copyto is inconsistent,",correctness issue ,error ,test the broadcast method
https://github.com/cupy/cupy/issues/5809,Issue of insert value in large matrix bug #5809,,nan issue,special value bug,different results,fix code 
https://github.com/cupy/cupy/issues/5568,IndexError when convolving with float scalar #5568,,dtype issue if not int ,correctness issue ,error ,fix shapes containing 1
https://github.com/cupy/cupy/issues/5537,Issue in cupyx/scipy/ndimage/_spline_prefilter_core.py with min() operation in large arrays for cupyx.scipy.ndimage.map_coordinates #5537,,large arrays fail ,correctness issue ,error ,fix code 
https://github.com/cupy/cupy/issues/5320,cp.array turns some array into nan ? #5320,,nan issue big endian issue ,special value bug,different results,big endian to little endian
https://github.com/cupy/cupy/issues/5315,cupy.nanmedian bug report #5315,,parameter issue,correctness issue ,different results,fix the parameter axis
https://github.com/cupy/cupy/issues/5246,Wrong behavior of cupy.random.Generator.integers #5246,,"correctness issue/diff is subtracted twice,",correctness issue ,different results,remove duplicate codes
https://github.com/cupy/cupy/issues/5175,CSC matrix constructor bug #5175,,zero issue,correctness issue ,error ,alternate solution
https://github.com/cupy/cupy/issues/4896,Slow sum/mean/max/... matrix operations compared to PyTorch #4896,,build problems cupy mean and max operations ,correctness issue ,slow perforamnce,use different libraries
https://github.com/cupy/cupy/issues/4891,[Issue] cp.matmul slower than np.matmul ?? #4891,,build problems(double precision) performance in gpu,environmental issue ,slow perforamnce,change to F32
https://github.com/cupy/cupy/issues/4550,ndimage.map_coordinates performs incorrectly with several order values #4550,,rounding off issue at half integer case,accuracy issue ,incorrect results,version change
https://github.com/cupy/cupy/issues/4136,the get function of the sparse matrix csr with stream does not give excepted result. #4136,,build issue in get function,correctness issue ,wrong results,fix the streams
https://github.com/cupy/cupy/issues/4082,Compilation error with cval=cp.nan in scipy.ndimage.interpolation.shift #4082,,"no support np.nan, np.inf or -np.inf compilation failure ",special value bug,compile error,build the support
https://github.com/cupy/cupy/issues/3984,cupy.cumsum unable to cast argument from list to cupy.ndarray in 8.0.0rc1 #3984,,operator issue,correctness issue ,error ,use explicit array
https://github.com/cupy/cupy/issues/3931,Performance issue : cupy is 800 times slower than numpy in linalg.solve() #3931,,implementation issue,correctness issue ,slow perforamce,add support
https://github.com/cupy/cupy/issues/3325,cupy.put behaves differently than numpy.put #3325,,failure in the method in cupy not in numpy,correctness issue ,error ,fix method for scalar inputs 
https://github.com/cupy/cupy/issues/3232,Lexsort output is incorrect #3232,,more support for all data types,correctness issue ,wrong results,fix cupy.cuda.thrust
https://github.com/cupy/cupy/issues/6255,Wrong index calculation in constructing sparse random matrix #6255,,rounding errors,accuracy issue,crash ,fix the implementation 
https://github.com/cupy/cupy/issues/6214,Undefined behavior on overlapping matmul out #6214,,produces undefined behavior ,correctness issue ,wrong results,fix the code 
https://github.com/cupy/cupy/issues/6207,Unable to convert some constants in cupy.jit #6207,,unable to convert constants ,correctness issue ,crash/error ,fix the implementation 
https://github.com/cupy/cupy/issues/5909,ndarray.clip signature does not match NumPy #5909,,ndarray.clip does not work when switching to cupy and numpy,correctness issue ,fail,add the necessary implementation for cupy and numpy
https://github.com/cupy/cupy/issues/5831,Random State returning inconsistent results #5831,, cp.random.RandomState results incorrect,correctness issue ,incorrect results,fix the implementation 
https://github.com/cupy/cupy/issues/5716,Incorrect output of cupy.logaddexp() #5716,,returns nan ,special value bugs,inccorect results,change the values 
https://github.com/cupy/cupy/issues/5704,Edge cases of compatibility in numpy.eye() #5704,,cp fails but numpy is not,correctness issue ,error ,fix cp.eye method
https://github.com/cupy/cupy/issues/5647,cp.unique gives IndexError when passed an empty array. #5647,,raise error with empty arrays,correctness issue ,error ,fix cp.unique
https://github.com/cupy/cupy/issues/5580,copyto bool array from complex array #5580,,casting issue,accuracy issue ,different results ,fix casting
https://github.com/cupy/cupy/issues/5527,unsafe cast from complex becomes NVRTC compile error #5527,,unsafe cast issue ,accuracy issue ,compile error ,fix casting
https://github.com/cupy/cupy/issues/5466,Random Generator wrong values for larger sizes more than 1d #5466,,random generator generates wrong value,correctness issue ,incorrect results,array only supports 1d
https://github.com/cupy/cupy/issues/5328,Unexpected error while assigning array element #5328,,singed interger overflow,accuracy issue ,compile error ,fix array indexing 
https://github.com/cupy/cupy/issues/5296,Get segmentation fault with FFT callback function #5296,,enivronment does not support ,environmental issue ,error ,add support to environment 
,,,,,,
